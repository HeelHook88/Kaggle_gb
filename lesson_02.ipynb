{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import scipy.stats as st\n",
    "from scipy.stats import probplot, ks_2samp\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "import missingno as msno\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape = 180000 rows, 394 cols\n",
      "test.shape = 100001 rows, 394 cols\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./datasets/assignment_2_train.csv\")\n",
    "test = pd.read_csv(\"./datasets/assignment_2_test.csv\")\n",
    "print(\"train.shape = {} rows, {} cols\".format(*train.shape))\n",
    "print(\"test.shape = {} rows, {} cols\".format(*test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "\n",
       "   card2  card3       card4  card5  ... V330  V331  V332  V333  V334 V335  \\\n",
       "0    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "2  490.0  150.0        visa  166.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "3  567.0  150.0  mastercard  117.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "4  514.0  150.0  mastercard  102.0  ...  0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "\n",
       "  V336  V337  V338  V339  \n",
       "0  NaN   NaN   NaN   NaN  \n",
       "1  NaN   NaN   NaN   NaN  \n",
       "2  NaN   NaN   NaN   NaN  \n",
       "3  NaN   NaN   NaN   NaN  \n",
       "4  0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'isFraud'\n",
    "var_names = train.columns.to_list()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of numerical features 378\n",
      "count of categorical features 14\n"
     ]
    }
   ],
   "source": [
    "num_features = train[var_names].select_dtypes(include=[np.number]).columns.to_list()\n",
    "cat_features = train[var_names].select_dtypes(include=[np.object]).columns.to_list()\n",
    "\n",
    "print(f'count of numerical features {len(num_features)}')\n",
    "print(f'count of categorical features {len(cat_features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGenerator:\n",
    "    def __init__(self, cat_features):\n",
    "        self.cat_features = cat_features\n",
    "        self.new_cat_features = []\n",
    "        self.lgb_cat_features = []\n",
    "        self.target_encodings = dict()\n",
    "        self.ordinal_encoding = dict()\n",
    "        \n",
    "        \n",
    "    def fit(self, train):\n",
    "        df = train.copy()\n",
    "        for feature in self.cat_features: \n",
    "            new_feature = feature + '_'\n",
    "            lgb_feature = feature + 'lgb'\n",
    "            self.new_cat_features.append(new_feature)\n",
    "            self.lgb_cat_features.append(lgb_feature)            \n",
    "            self.target_encodings[feature] = {}\n",
    "            self.ordinal_encoding[feature] = {}\n",
    "            for ind, level in enumerate(df[feature].unique()):\n",
    "                level_value = df.loc[df[feature]==level, target].mean()\n",
    "                self.target_encodings[feature][level] = level_value\n",
    "                self.ordinal_encoding[feature][level] = ind\n",
    "                \n",
    "    def transform(self, df):\n",
    "        for feature in self.cat_features: \n",
    "            for level in self.target_encodings[feature].keys():\n",
    "                new_feature = feature + '_'\n",
    "                lgb_feature = feature + 'lgb'\n",
    "                df.loc[df[feature] == level, new_feature] = self.target_encodings[feature][level]\n",
    "                df.loc[df[feature] == level, lgb_feature] = self.ordinal_encoding[feature][level]\n",
    "                \n",
    "        df[cat_features] = df[cat_features].astype(str)  \n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(train, \n",
    "                                      shuffle=True,\n",
    "                                      stratify=train[target],\n",
    "                                      test_size=0.2,\n",
    "                                      random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = FeatureGenerator(cat_features)\n",
    "features.fit(df_train)\n",
    "df_train = features.transform(df_train)\n",
    "df_valid = features.transform(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = FeatureGenerator(cat_features)\n",
    "features.fit(train)\n",
    "train = features.transform(train)\n",
    "test = features.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1: отобрать только числовые признаки и обучить модель XGBoost с параметром booster = gbtree. Обучать алгоритм до тех пор, пока метрика качества не перестанет улучшаться на валидационной выборке в течение определенного числа итераций (выбрать значение самостоятельно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {\"booster\": \"gbtree\", \n",
    "              \"objective\": \"binary:logistic\", \n",
    "              \"eval_metric\": \"auc\", \n",
    "              \"learning_rate\": 0.1, \n",
    "              \"n_estimators\": 1000, \n",
    "              \"reg_lambda\": 100, \n",
    "              \"max_depth\": 4, \n",
    "              \"gamma\": 10, \n",
    "              \"nthread\": -1, \n",
    "              \"seed\": 27}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:17:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.64850\tvalid-auc:0.65575\n",
      "[50]\ttrain-auc:0.88045\tvalid-auc:0.88507\n",
      "[100]\ttrain-auc:0.89836\tvalid-auc:0.89863\n",
      "[150]\ttrain-auc:0.90670\tvalid-auc:0.90349\n",
      "[200]\ttrain-auc:0.90770\tvalid-auc:0.90416\n",
      "[208]\ttrain-auc:0.90770\tvalid-auc:0.90416\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(data=df_train[num_features], label=df_train[target])\n",
    "dvalid = xgb.DMatrix(data=df_valid[num_features], label=df_valid[target])\n",
    "\n",
    "model_xgb_num = xgb.train(params=params_xgb,\n",
    "                          dtrain=dtrain,\n",
    "                          evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "                          num_boost_round=1000,\n",
    "                          early_stopping_rounds=50,  \n",
    "                          verbose_eval=50,\n",
    "                          maximize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2: обработать категориальные признаки любым способом (который вы знаете) и добавить их к данным. Выполнить задание 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature = num_features + features.new_cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:18:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.64850\tvalid-auc:0.65575\n",
      "[50]\ttrain-auc:0.88842\tvalid-auc:0.89343\n",
      "[100]\ttrain-auc:0.90786\tvalid-auc:0.90642\n",
      "[150]\ttrain-auc:0.91562\tvalid-auc:0.91143\n",
      "[200]\ttrain-auc:0.91648\tvalid-auc:0.91182\n",
      "[205]\ttrain-auc:0.91648\tvalid-auc:0.91182\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(data=df_train[new_feature], label=df_train[target])\n",
    "dvalid = xgb.DMatrix(data=df_valid[new_feature], label=df_valid[target])\n",
    "\n",
    "model_xgb_num = xgb.train(params=params_xgb,\n",
    "                          dtrain=dtrain,\n",
    "                          evals=[(dtrain, \"train\"), (dvalid, \"valid\")],\n",
    "                          num_boost_round=1000,\n",
    "                          early_stopping_rounds=50,  \n",
    "                          verbose_eval=50,\n",
    "                          maximize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3: для числовых признаков обучить модель LightGBM. Обучать алгоритм до тех пор, пока метрика качества не перестанет улучшаться на валидационной выборке в течение определенного числа итераций (выбрать значение самостоятельно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb = {\"boosting_type\": \"gbdt\",\n",
    "              \"objective\": \"binary\",\n",
    "              \"metric\": \"auc\",\n",
    "              \"num_boost_round\": 10000,  \n",
    "              \"learning_rate\": 0.01,\n",
    "              \"n_estimators\": 1000,\n",
    "              \"n_jobs\": -1,\n",
    "              \"seed\": 27}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4113, number of negative: 139887\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.198421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 31662\n",
      "[LightGBM] [Info] Number of data points in the train set: 144000, number of used features: 376\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028563 -> initscore=-3.526682\n",
      "[LightGBM] [Info] Start training from score -3.526682\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[500]\ttraining's auc: 0.944346\tvalid_1's auc: 0.925079\n",
      "[1000]\ttraining's auc: 0.967873\tvalid_1's auc: 0.936432\n",
      "[1500]\ttraining's auc: 0.978256\tvalid_1's auc: 0.941325\n",
      "[2000]\ttraining's auc: 0.98426\tvalid_1's auc: 0.944706\n",
      "[2500]\ttraining's auc: 0.988283\tvalid_1's auc: 0.947384\n",
      "[3000]\ttraining's auc: 0.991717\tvalid_1's auc: 0.949577\n",
      "[3500]\ttraining's auc: 0.993659\tvalid_1's auc: 0.951199\n",
      "Early stopping, best iteration is:\n",
      "[3888]\ttraining's auc: 0.994793\tvalid_1's auc: 0.95254\n"
     ]
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(data=df_train[num_features], label=df_train[target])\n",
    "dvalid = lgb.Dataset(data=df_valid[num_features], label=df_valid[target])\n",
    "\n",
    "model_lgb_num = lgb.train(params=params_lgb,\n",
    "                          train_set=dtrain,  \n",
    "                          valid_sets=[dtrain, dvalid],\n",
    "                          categorical_feature=\"auto\",\n",
    "                          verbose_eval=500,\n",
    "                          early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4: обработать категориальные признаки любым способом (который вы знаете) и добавить их к данным. Выполнить задание 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4113, number of negative: 139887\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 31768\n",
      "[LightGBM] [Info] Number of data points in the train set: 144000, number of used features: 390\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028563 -> initscore=-3.526682\n",
      "[LightGBM] [Info] Start training from score -3.526682\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[500]\ttraining's auc: 0.954435\tvalid_1's auc: 0.935091\n",
      "[1000]\ttraining's auc: 0.973527\tvalid_1's auc: 0.944858\n",
      "[1500]\ttraining's auc: 0.983757\tvalid_1's auc: 0.949055\n",
      "[2000]\ttraining's auc: 0.989681\tvalid_1's auc: 0.952462\n",
      "[2500]\ttraining's auc: 0.993322\tvalid_1's auc: 0.95553\n",
      "[3000]\ttraining's auc: 0.995438\tvalid_1's auc: 0.956912\n",
      "[3500]\ttraining's auc: 0.996797\tvalid_1's auc: 0.958178\n",
      "[4000]\ttraining's auc: 0.997796\tvalid_1's auc: 0.959084\n",
      "Early stopping, best iteration is:\n",
      "[4330]\ttraining's auc: 0.998209\tvalid_1's auc: 0.959647\n"
     ]
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(data=df_train[new_feature], label=df_train[target])\n",
    "dvalid = lgb.Dataset(data=df_valid[new_feature], label=df_valid[target])\n",
    "\n",
    "model_lgb_num = lgb.train(params=params_lgb,\n",
    "                          train_set=dtrain,  \n",
    "                          valid_sets=[dtrain, dvalid],\n",
    "                          categorical_feature=\"auto\",\n",
    "                          verbose_eval=500,\n",
    "                          early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 5: обработать категориальные признаки встроенным методом в LightGBM. Выполнить задание 3. Сделать выводы о качестве работы алгоритма, по сравнению с пунктом 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_features = num_features + features.lgb_cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 4113, number of negative: 139887\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 31835\n",
      "[LightGBM] [Info] Number of data points in the train set: 144000, number of used features: 390\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.028563 -> initscore=-3.526682\n",
      "[LightGBM] [Info] Start training from score -3.526682\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[500]\ttraining's auc: 0.955084\tvalid_1's auc: 0.933298\n",
      "[1000]\ttraining's auc: 0.974084\tvalid_1's auc: 0.944636\n",
      "[1500]\ttraining's auc: 0.983933\tvalid_1's auc: 0.948529\n",
      "[2000]\ttraining's auc: 0.989812\tvalid_1's auc: 0.951704\n",
      "[2500]\ttraining's auc: 0.993409\tvalid_1's auc: 0.953856\n",
      "[3000]\ttraining's auc: 0.995338\tvalid_1's auc: 0.955657\n",
      "[3500]\ttraining's auc: 0.996915\tvalid_1's auc: 0.957256\n",
      "Early stopping, best iteration is:\n",
      "[3794]\ttraining's auc: 0.997497\tvalid_1's auc: 0.957705\n"
     ]
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(data=df_train[lgbm_features], \n",
    "                     label=df_train[target], \n",
    "                     categorical_feature=features.lgb_cat_features)\n",
    "\n",
    "dvalid = lgb.Dataset(data=df_valid[lgbm_features], \n",
    "                     label=df_valid[target],\n",
    "                     categorical_feature=features.lgb_cat_features)\n",
    "\n",
    "model_lgb_all_cat = lgb.train(params=params_lgb,\n",
    "                              train_set=dtrain,  \n",
    "                              valid_sets=[dtrain, dvalid],\n",
    "                              categorical_feature=features.lgb_cat_features,\n",
    "                              verbose_eval=500,\n",
    "                              early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: Обработка категориальных признаков встроенным в LightGBM методом дает не худший результат\n",
    "по сравнению с target encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 6: для числовых признаков обучить модель CatBoost. Обучать алгоритм до тех пор, пока метрика качества не перестанет улучшаться на валидационной выборке в течение определенного числа итераций (выбрать значение самостоятельно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cb = {\"n_estimators\":5000,\n",
    "             \"loss_function\": \"Logloss\",\n",
    "             \"eval_metric\": \"AUC\",\n",
    "             \"task_type\": \"CPU\",\n",
    "             \"max_bin\": 30,\n",
    "             \"early_stopping_rounds\": 50,\n",
    "             \"verbose\": 500,\n",
    "             \"max_depth\": 5,\n",
    "             \"l2_leaf_reg\": 100,             \n",
    "             \"thread_count\": 6,\n",
    "             \"random_seed\": 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6778214\tbest: 0.6778214 (0)\ttotal: 51.4ms\tremaining: 4m 16s\n",
      "500:\ttest: 0.8895358\tbest: 0.8895495 (472)\ttotal: 27.1s\tremaining: 4m 3s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8895494801\n",
      "bestIteration = 472\n",
      "\n",
      "Shrink model to first 473 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x150acb6b9a0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = cb.Pool(df_train[num_features], label=df_train[target])\n",
    "dvalid = cb.Pool(df_valid[num_features], label=df_valid[target])\n",
    "\n",
    "model_cb_num = cb.CatBoostClassifier(**params_cb)\n",
    "model_cb_num.fit(dtrain, eval_set=dvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 7: обработать категориальные признаки любым способом (который вы знаете) и добавить их к данным. Выполнить задание 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6806710\tbest: 0.6806710 (0)\ttotal: 55.6ms\tremaining: 4m 37s\n",
      "500:\ttest: 0.8996157\tbest: 0.8996157 (500)\ttotal: 27.1s\tremaining: 4m 3s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9026456852\n",
      "bestIteration = 730\n",
      "\n",
      "Shrink model to first 731 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x15098678f10>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = cb.Pool(df_train[new_feature], label=df_train[target])\n",
    "dvalid = cb.Pool(df_valid[new_feature], label=df_valid[target])\n",
    "\n",
    "model_cb_all = cb.CatBoostClassifier(**params_cb)\n",
    "model_cb_all.fit(dtrain, eval_set=dvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 8: обработать категориальные признаки встроенным методом в CatBoost. Выполнить задание 6. Сделать выводы о качестве работы алгоритма, по сравнению с пунктом 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7309429\tbest: 0.7309429 (0)\ttotal: 207ms\tremaining: 17m 16s\n",
      "500:\ttest: 0.8978831\tbest: 0.8978831 (500)\ttotal: 1m 37s\tremaining: 14m 38s\n",
      "1000:\ttest: 0.9015727\tbest: 0.9015733 (985)\ttotal: 3m 22s\tremaining: 13m 29s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9015732736\n",
      "bestIteration = 985\n",
      "\n",
      "Shrink model to first 986 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x15099518d90>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = cb.Pool(df_train[var_names], \n",
    "                 label=df_train[target], \n",
    "                 cat_features=cat_features)\n",
    "dvalid = cb.Pool(df_valid[var_names], \n",
    "                 df_valid[target], \n",
    "                 cat_features=cat_features)\n",
    "\n",
    "model_cb_all_cat = cb.CatBoostClassifier(**params_cb)\n",
    "model_cb_all_cat.fit(dtrain, eval_set=dvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: Использование встроенного метода обработки категориальных переменных catboost, дает похожий результат с target encoding и увеличивает время обучения."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
